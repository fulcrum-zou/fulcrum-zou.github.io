<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2049/01/hello-world/</url>
    <content><![CDATA[<p>hello, world!</p>
<p>我会在这里记录一些日常随笔、生活片段、技术博客、摄影作品…</p>
<p>主要还是供自己查阅.</p>
<p>如果这里的posts不小心帮助到了你，那么我很荣幸！</p>
]]></content>
      <categories>
        <category>2049</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>This Is Just To Say</title>
    <url>/2021/06/This-Is-Just-To-Say/</url>
    <content><![CDATA[<p>一首小诗.</p>
<span id="more"></span>
<html>

  <style>
    #poem {
      position: relative;
      font-family: 'Optima';
      color: dimgray;
      font-size: 20px;
      text-align: left;
      line-height: 30px;
      margin-top: 60px;
      margin-bottom: 60px;
      width: 50%;
      left: 25%;
      white-space: nowrap;
    }
    #title {
      font-weight: bold;
      font-size: 25px;
        margin-bottom: 50px;
      }
    #author {
      font-size: 21px;
      margin-top: 60px;
    }
    #plums {
      color: #7b2945;
    }
  </style>

<div id='poem'>
  <div id='title'>
    <p>This Is Just To Say</p >
  </div>
  <div id='content'>
    <p id='p1'>
      I have eaten <br>
      the <span id='plums'>plums</span> <br>
      that were in <br>
      the icebox <br>
    </p >
    <p id='p2'>
      and which <br>
      you were probably <br>
      saving <br>
      for breakfast <br>
    </p >
    <p id='p3'>
      Forgive me <br>
      they were delicious <br>
      so sweet <br>
      and so cold <br>
    </p >
  </div>
  <div id='author'>
    <p>
      William Carlos Williams
    </p >
  </div>
</div>

</html>

]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title>数字口译</title>
    <url>/2021/06/number-interpreting-skills/</url>
    <content><![CDATA[<p>今天下午的口译课讲了数字相关的英汉互译，做了很多练习，其中还有一大段非常致命的印度口音. 在有限的1.5小时中，我勉强摸索出了一些数字口译的技巧，所以顺便记录一下！</p>
<span id="more"></span>
<h2 id="1-常用单位互译"><a href="#1-常用单位互译" class="headerlink" title="1 常用单位互译"></a>1 常用单位互译</h2><ul>
<li>En-&gt;中</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>English</th>
<th>中文</th>
<th>Arabic Numerals</th>
<th>阿拉伯数字</th>
</tr>
</thead>
<tbody>
<tr>
<td>10 thousand</td>
<td>1万</td>
<td>10, 000</td>
<td>1, 0000</td>
</tr>
<tr>
<td>1 million</td>
<td>1百万</td>
<td>1, 000, 000</td>
<td>100, 0000</td>
</tr>
<tr>
<td>10 million</td>
<td>1千万</td>
<td>10, 000, 000</td>
<td>1000, 0000</td>
</tr>
<tr>
<td>100 million</td>
<td>1亿</td>
<td>100, 000, 000</td>
<td>1, 0000, 0000</td>
</tr>
<tr>
<td>100 billion</td>
<td>1千亿</td>
<td>100, 000, 000, 000</td>
<td>1000, 0000, 0000</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>中-&gt;En</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>中文</th>
<th>English</th>
<th>阿拉伯数字</th>
<th>Arabic Numerals</th>
</tr>
</thead>
<tbody>
<tr>
<td>1千</td>
<td>1 thousand</td>
<td>1000</td>
<td>1, 000</td>
</tr>
<tr>
<td>100万</td>
<td>1 million</td>
<td>100, 0000</td>
<td>1, 000, 000</td>
</tr>
<tr>
<td>10亿</td>
<td>1 billion</td>
<td>10, 0000, 0000</td>
<td>1, 000, 000, 000</td>
</tr>
<tr>
<td>10000亿</td>
<td>1 trillion</td>
<td>1, 0000, 0000, 0000</td>
<td>1, 000, 000, 000, 000</td>
</tr>
</tbody>
</table>
</div>
<p>记住它们！</p>
<h2 id="2-练习"><a href="#2-练习" class="headerlink" title="2 练习"></a>2 练习</h2><p>我总结出的步骤如下：</p>
<ol>
<li>记笔记 (数字 + 单位)</li>
<li>根据上面的表格按单位划分 (系数｜单位)<ul>
<li>英译中用<code>En-&gt;中</code>表，根据<code>English</code>一列划分单位</li>
<li>中译英用<code>中-&gt;En</code>表，根据<code>中文</code>一列划分单位</li>
</ul>
</li>
<li>换算一下，即系数$\times$单位</li>
<li>再整理一下就可以得到答案了</li>
</ol>
<p>有点抽象，所以举一些例子！</p>
<h3 id="2-1-英译中"><a href="#2-1-英译中" class="headerlink" title="2.1 英译中"></a>2.1 英译中</h3><ul>
<li><p>Eighty million three hundred and two thousand five hundred and eight</p>
<p>笔记：80m 302t 508</p>
<p>划分：8｜0m，30｜2t，508</p>
<p>换算：8千万，30万，2千，508</p>
<p>翻译：八千零三十万两千五百零八</p>
</li>
<li><p>Two million nine thousand and five</p>
<p>笔记：2m 9t 5</p>
<p>划分：2｜m，9｜t，5</p>
<p>换算：2百万，9千，5</p>
<p>翻译：两百万九千零五</p>
</li>
<li><p>Four hundred and seventy one point one billion</p>
<p>笔记：471.1b</p>
<p>划分：｜471.1b</p>
<p>换算：471.1$\times$1000亿$=$4711亿</p>
<p>翻译：四千七百一十一亿</p>
</li>
</ul>
<h3 id="2-2-中译英"><a href="#2-2-中译英" class="headerlink" title="2.2 中译英"></a>2.2 中译英</h3><ul>
<li><p>六万二千八百一十五亿</p>
<p>笔记：62815亿</p>
<p>划分：6｜281｜5亿</p>
<p>换算：6 trillion，281 billion，500 million (5差2位凑齐3位，补2个0)</p>
<p>翻译：Six trillion two hundredn and eighty one billion five hundred million</p>
</li>
<li><p>三千八百七十七万</p>
<p>笔记：3877万</p>
<p>划分：38｜77万</p>
<p>换算：38 million，770 thousand (77差1位凑齐3位，补1个0)</p>
<p>翻译：Thirty eight million seven hundred and seventy thousand</p>
</li>
<li><p>一万九千零四万</p>
<p>笔记：10904万</p>
<p>划分：109｜04万</p>
<p>换算：109 million, 40 thousand (04差1位凑齐3位，补1个0)</p>
<p>翻译：One hundred and nine million and fourty thousand</p>
</li>
</ul>
<p><br></p>
<p><br><br>PS：这套方法没有经历过普适性的检验，所以慎用！ 而且经过一下午的实践，我发现这套方法比较适用于中译英，大部分英译中还是写成阿拉伯数字再翻译比较快. 原因可能是本人从小搞不清中文数字单位…</p>
]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>杂记</tag>
        <tag>口译</tag>
      </tags>
  </entry>
  <entry>
    <title>色度二次采样</title>
    <url>/2021/05/chroma-subsampling/</url>
    <content><![CDATA[<p>色度二次采样 (chroma subsampling) 是在图像压缩中用到的一项技术，二次采样后的图像损失了色度信息，占用空间变小. 对于YCbCr色彩空间的图像，由于人眼对色度(chrominance)的变化不如对亮度(luminance)的变化敏感，所以可以对色度信息进行采样来减少图像数据的大小. 其中，Y通道表示亮度，Cb和Cr通道表示色度.</p>
<span id="more"></span>
<h2 id="二次采样率"><a href="#二次采样率" class="headerlink" title="二次采样率"></a>二次采样率</h2><p>色度二次采样率由$J:a:b$三部分组成.</p>
<p>偶尔会看到由四部分组成的二次采样率，这是因为加入了表示透明度的alpha通道，这里不做讨论.</p>
<p>二次采样率表示由两行组成的采样块中如何采样.</p>
<p>$J$表示采样块为$J$像素宽.</p>
<p>$a$表示采样块的第一行中采样几个像素.</p>
<p>$b$表示采样块的第二行中采样几个像素.</p>
<p>常见的色度采样方案有$4:4:4$、$4:2:2$、$4:1:1$、$4:2:0$.</p>
<p>考虑下图，对YCbCr格式的图像进行采样，所有像素都保留了Y通道的信息，只对色度通道进行二次采样：</p>
<p><img src="https://i.loli.net/2021/05/31/zFjiS32b4Qk6Boy.png" alt="image.png" style="zoom:40%;" /></p>
<h3 id="4-4-4"><a href="#4-4-4" class="headerlink" title="$4:4:4$"></a>$4:4:4$</h3><p>即不进行二次采样，保留100%的颜色信息.</p>
<h3 id="4-2-2"><a href="#4-2-2" class="headerlink" title="$4:2:2$"></a>$4:2:2$</h3><p>第一行的水平方向每4个像素中保留2个像素的Cb和Cr通道的信息.</p>
<p>第二行同理.</p>
<h3 id="4-1-1"><a href="#4-1-1" class="headerlink" title="$4:1:1$"></a>$4:1:1$</h3><p>第一行的水平方向每4个像素中保留1个像素的Cb和Cr通道的信息.</p>
<p>第二行同理</p>
<h3 id="4-2-0"><a href="#4-2-0" class="headerlink" title="$4:2:0$"></a>$4:2:0$</h3><p>这种色度二次采样率是JPEG压缩中常用的.</p>
<p>第一行的水平方向每4个像素中保留2个像素的Cb和Cr通道的信息.</p>
<p>第二行的水平方向每4个像素中所有Cb和Cr通道的信息都不保留.</p>
<p>图中表示的是，取第一行与第二行的Cb和Cr通道信息的平均值.</p>
]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>图像处理</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱——关系抽取</title>
    <url>/2021/05/knowledge-graph-relation-extraction/</url>
    <content><![CDATA[<p>本文介绍 Random Walk Algorithm 与 Path Ranking Algorithm 在知识图谱关系抽取中的应用.</p>
<span id="more"></span>
<h2 id="1-Random-Walk-Algorithm"><a href="#1-Random-Walk-Algorithm" class="headerlink" title="1 Random Walk Algorithm"></a>1 Random Walk Algorithm</h2><h3 id="1-1-一点有趣的背景"><a href="#1-1-一点有趣的背景" class="headerlink" title="1.1 一点有趣的背景"></a>1.1 一点有趣的背景</h3><p>Random Walk(随机游走)的概念很早就有了，不过在1973年于一本叫 <em>A Random Walk Down Wall Street</em> 的书中得到了广泛的应用. 该书认为股市的走向是随机的 (“Stocks take a random path”)，难以预测，其难度堪比预测一个酒鬼下一步会走向哪里. 书中认为股票的价格是独立同分布的，因此不能假设过去的股市走向可以用来预测未来.</p>
<h3 id="1-2-进入正题"><a href="#1-2-进入正题" class="headerlink" title="1.2 进入正题"></a>1.2 进入正题</h3><p>这里用一维的随机游走模型来举个例子：</p>
<p>设一条直线上有$n$个点，依次为$1,2,\dots,n$. 在当前时刻$t$，有一个质点$A$位于点$i$. 那么在$t+1$时刻，质点$A$的位置可能有：</p>
<ol>
<li>以$p$的概率走到点$i-1$.</li>
<li>以$(1-p)$的概率走到点$i+1$.</li>
</ol>
<p>理论看上去非常简单… 不过还有一些关于期望和概率分布的计算比较有趣，计算过程挺简单的，本文不再叙述，具体可以看看<a href="https://www.mit.edu/~kardar/teaching/projects/chemotaxis%28AndreaSchmidt%29/random.htm">这里</a>.</p>
<p>随机游走要解决的问题是，给定一个连接图及图中每个节点的转移概率，找到从某个点开始随机走动，最后停留在每个点的概率分布.</p>
<p>其求解的具体过程为：在任意一个顶点，以概率$1-p$走到这个顶点的邻居顶点，以概率$p$随机跳跃到图中的任何一个顶点，称$p$为跳转发生概率. 每次游走后得出一个概率分布，该概率分布刻画了图中每一个顶点被访问到的概率。用这个概率分布作为下一次游走的输入并反复迭代这一过程。当满足一定前提条件时，这个概率分布会趋于收敛，可以得到一个平稳的概率分布.</p>
<h3 id="1-3-Random-Walk-with-Restart"><a href="#1-3-Random-Walk-with-Restart" class="headerlink" title="1.3 Random Walk with Restart"></a>1.3 Random Walk with Restart</h3><p>Random Walk with Restart (重启随机游走)考虑了回到<em>起始点</em>的概率概率分布，即下一跳有一定的概率回到起始点，称为重启概率.</p>
<p>设一个连接图有$n$个节点，则以$i$为起点，到达图中各个节点概率分布$\boldsymbol{r}\in\mathbb{R}^{n\times1}$可以由下式定义：</p>
<script type="math/tex; mode=display">
\boldsymbol{r}=(1-d)\boldsymbol{u}+d\boldsymbol{W}\boldsymbol{r}.</script><p>其中，$1-d$是重启概率，$W$是转移矩阵，$\boldsymbol{u}$是为one-hot的起点向量.</p>
<p>上式的解可以通过迭代地计算下式得到：</p>
<script type="math/tex; mode=display">
\boldsymbol{r}^t=(1-d)\boldsymbol{u}+d\boldsymbol{W}\boldsymbol{r}^{t-1}.</script><p>以图中每个节点各为起点做一次RWR得到$\boldsymbol{r}$，则可以表示点之间的相关性.</p>
<h3 id="1-4-两个简单的应用"><a href="#1-4-两个简单的应用" class="headerlink" title="1.4 两个简单的应用"></a>1.4 两个简单的应用</h3><ol>
<li><p>图嵌入</p>
<ul>
<li><p>DeepWalk</p>
<p>将图信息转化为向量嵌入. 使用随机游走生成节点序列，将图数据转化为一段类似自然语言的序列，然后用Word2Vec的模型得到每个节点的向量.</p>
</li>
<li><p>Node2Vec</p>
<p>DeepWalk完全随机，而Node2Vec用两个参数控制随机游走下一跳的概率分配.</p>
</li>
</ul>
</li>
<li><p>分类</p>
<p>分别从A类型的节点与B类型的节点开始做RWR，如果RWR(A)数值比RWR(B)大，则将该节点归为A类，反之归为B类.</p>
</li>
</ol>
<h2 id="2-Path-Ranking-Algorithm"><a href="#2-Path-Ranking-Algorithm" class="headerlink" title="2 Path Ranking Algorithm"></a>2 Path Ranking Algorithm</h2><h3 id="2-1-背景"><a href="#2-1-背景" class="headerlink" title="2.1 背景"></a>2.1 背景</h3><p>Path Ranking Algorithm (PRA) 在 <em>Relational Retrieval Using a Combination of Path-Constrained Random Walks</em> (<a href="https://sci-hub.do/10.1007/s10994-010-5205-8">Lao and Cohen, 2010b</a>) 一文中提出. 它想要解决的问题是，给定知识图谱与查询，得到图中与之相关的节点，即语义上相似(proximity)的节点. </p>
<blockquote>
<p>  “… <em>ad hoc</em> retrieval or named entity recognition (NER) to be formulated as <em>typed proximity queries</em> in the graph.”</p>
</blockquote>
<p>不同于以往常用的有监督的重启随机游走(RWR)，给每个边一个权重，</p>
<blockquote>
<p>  “… associating each edge label with a parameter.”</p>
</blockquote>
<p>PRA给出一组边序列，并给它们打分，然后再做加权，加权得到的结果用于衡量相似度.</p>
<blockquote>
<p>“… a novel learnable proximity measure which instead uses one weight per edge label <em>sequence</em>: proximity is defined by a weighted combination of simple “path experts”, each corresponding to following a particular sequence of labeled edges.”</p>
</blockquote>
<p>RWR的局限性是，忽略了边的上下文. 例如，给定年份$y$，要查询合适的参考文献. 那么有两种方式：(H1) $y$年发表的论文；(H2) $y$年发表的论文中被引用最多的. 直觉上，H2更好. 但RWR只能考虑到”发表于”(<em>PublishedIn</em>)，考虑不到”被引用”(“<em>Cite</em>“)</p>
<h3 id="2-2-任务"><a href="#2-2-任务" class="headerlink" title="2.2 任务"></a>2.2 任务</h3><p>该论文的任务背景是：用有标签的有向图来表示科学文献，其中不同类别的节点可以表示文档、术语、元数据，不同标签的边可以表示节点之间的关系，可以解决 typed oriximity queries. 给定查询节点(query nodes)和答案类型(answer type)作为输入，可以得到一组符合答案类型的节点作为输出，且按照与查询节点的相似度排序.</p>
<p>该论文考虑了4个任务：</p>
<ol>
<li><p>会议推荐 (venue recommendation)</p>
<p>任务目标：查询一篇新的论文适合发表的会议</p>
<p>查询节点：论文的标题与术语、一组与论文相关的实体 (基因或蛋白质)、当前年份</p>
<p>答案类型：期刊 (“journal”)</p>
</li>
<li><p>引用推荐 (reference recommendation)</p>
<p>任务目标：查询一篇新论文相关的参考文献</p>
<p>查询节点：同任务1</p>
<p>答案类型：论文 (“paper”)</p>
</li>
<li><p>专家寻找 (expert finding)</p>
<p>任务目标：寻找某个特定的专家</p>
<p>查询节点：术语、实体、当前年份</p>
<p>答案类型：人 (“person”)</p>
</li>
<li><p>基因推荐 (gene recommendation)</p>
<p>任务目标：根据某个作者以往的发表，预测他之后发表文章将涉及的基因</p>
<p>查询节点：作者、年份</p>
<p>答案类型：基因 (“gene”)</p>
</li>
</ol>
<h3 id="2-3-方法"><a href="#2-3-方法" class="headerlink" title="2.3 方法"></a>2.3 方法</h3><h4 id="2-3-1-符号定义"><a href="#2-3-1-符号定义" class="headerlink" title="2.3.1 符号定义"></a>2.3.1 符号定义</h4><div class="table-container">
<table>
<thead>
<tr>
<th>符号</th>
<th>意义</th>
</tr>
</thead>
<tbody>
<tr>
<td>$e$</td>
<td>实体(节点).</td>
</tr>
<tr>
<td>$R(e,e’)$</td>
<td>$e$与$e’$之间的关系$R$.</td>
</tr>
<tr>
<td>$R(e)$</td>
<td>满足$R(e,e’)$的$e’$,</td>
</tr>
<tr>
<td>$dom(R)$</td>
<td>$R$的定义域,</td>
</tr>
<tr>
<td>$range(R)$</td>
<td>$R$的值域.</td>
</tr>
<tr>
<td>$P$</td>
<td>由$R_1\dots R_l$构成的关系路径.</td>
</tr>
</tbody>
</table>
</div>
<p>$P$满足$range(R_i)\equiv dom(R_{i+1})$，且$dom(R_1\dots R_l)\equiv dom(R_1)$，$range(R_1\dots R_l)\equiv range(R_l)$.</p>
<p>一条路径$P=R_1\dots R_l$可以表示为：</p>
<script type="math/tex; mode=display">
T_0\xrightarrow{R_1}\dots\xrightarrow{R_l}\dots T_l,</script><p>其中，$T_0=dom(R_1)=dom(P)$，$T_1=range(R1)=dom(R_2)$.</p>
<p>此外，用$^{-1}$表示关系的逆，并且关系与关系的逆是不同的.</p>
<h4 id="2-3-2-具体算法"><a href="#2-3-2-具体算法" class="headerlink" title="2.3.2 具体算法"></a>2.3.2 具体算法</h4><p>给定关系路径$P=R_1\dots R_l$，一组查询节点$E_q\subset dom(P)$，可以计算图中节点$e$的分数$h_{E_q,P(e)}$：</p>
<ul>
<li><p>如果$P$为空</p>
<script type="math/tex; mode=display">
h_{E_q,P(e)}=
\begin{cases}
& \frac{1}{|E_q|} &,\text{if }e\in E_q \newline
& 0 &,\text{otherwise}
\end{cases}.</script></li>
<li><p>如果$P$非空</p>
<script type="math/tex; mode=display">
h_{E_q,P(e)}=\sum_{e'\in range(P')}h_{E_q,P'(e')}\cdot\frac{I(R_l(e',e))}{|R_l(e')|},</script><p>其中，</p>
<script type="math/tex; mode=display">
\begin{align}
& P'=R_1\dots R_{l-1}, \newline
& I(R_l(e',e))=
\begin{cases}
& 1 &,\text{if }e'\in dom(R_l) \newline
& 0 &,\text{otherwise}
\end{cases}.
\end{align}</script></li>
</ul>
<p>$\frac{1}{|E_q|}$和$\frac{I(R_l(e’,e))}{|R_l(e’)|}$可以大致理解为下一跳节点均匀分布的概率(稍微意会一下就好了).</p>
<p>总而言之，$h_{E_q,P(e)}$表示了给定一条关系路径和一组查询节点，图中某个节点的分数.</p>
<p>因此，考虑一组不同的关系路径$P_1,\dots,P_n$，并给出一组线性加权值$\theta_i$，我们可以对图中所有的$e$基于下式的结果排序：</p>
<script type="math/tex; mode=display">
\theta_1h_{E_q,P_1(e)}+\theta_2h_{E_q,P_2(e)}+\dots\theta_nh_{E_q,P_n(e)}.</script><p>给定查询节点$E_q$与答案类型$T_q$，对于固定的长度$l$，可以生成一组关系路径$\mathcal{P}(q,l)=\{P\}$，其中$\mathcal{P}$的值域包含于$T_q$.</p>
<p>因此，PRA就是用下列评分函数对所有符合答案类型的节点$e\in I(T_q)$进行排序：</p>
<script type="math/tex; mode=display">
s(e;\theta)=\sum_{P\in\mathcal{P}(q,l)}h_{E_q,P(e)}\theta_P.</script><p>上式可以写为矩阵形式$s=\boldsymbol{A}\theta$，其中$A$称为特征矩阵，$s$与$\theta$均为列向量，与不同的$P$对应.</p>
<h4 id="2-3-3-参数估计"><a href="#2-3-3-参数估计" class="headerlink" title="2.3.3 参数估计"></a>2.3.3 参数估计</h4><p>设训练集为$\mathcal{D}=\{(q^{(m)},r^{(m)})\},m=1,\dots,M$，其中，$r^{(m)}$为零一向量(binary vector). 如果节点$e$与查询$q^{(m)}$相关，那么$r_e^{(m)}=1$，反之为$0$.</p>
<p>优化目标为下式，运用了L2正则化：</p>
<script type="math/tex; mode=display">
O(\theta)=\sum_{m=1}^Mo^{(m)}(\theta)-\frac{\lambda}{2}|\theta|_2.</script><p>对于一个训练集$\mathcal{D}$中的第$m$条训练数据，设特征矩阵为$A^{(m)}$，与之相关的节点下标集合为$\mathcal{R}^{(m)}$，与之无关的节点下标集合为$\mathcal{N}^{(m)}$. 用二项分布的对数似然(binomial log-likelihood)来表示目标函数：</p>
<script type="math/tex; mode=display">
o^{(m)}(\theta)=\sum_{i\in\mathcal{R}^{(m)}}\frac{\ln p_i^{(m)}}{|\mathcal{R}^{(m)}|}+\sum_{i\in\mathcal{N}^{(m)}}\frac{\ln(1-p_i^{(m)})}{|\mathcal{N}^{(m)}|},</script><p>其中，$p_i^{(m)}=\sigma(\theta^TA_i^{(m)})$. 可以理解为将$s$分类为$r=1$与$r=0$，并且用sigmoid函数将其映射到$[0,1]$表示概率.</p>
<p>求导优化过程这里就不写了，具体的内容在论文的3.2节.</p>
<h4 id="2-3-4-延伸"><a href="#2-3-4-延伸" class="headerlink" title="2.3.4 延伸"></a>2.3.4 延伸</h4><p>论文中还提到了基于上述PRA的延伸：</p>
<ol>
<li>Query-Independent Experts</li>
<li>Popular Entity Experts</li>
</ol>
]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>NLP</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>Git上传至已有仓库</title>
    <url>/2021/05/push-to-existing-repository-with-git/</url>
    <content><![CDATA[<p>今天在做<a href="https://github.com/fulcrum-zou">Github的个人主页</a>，在本地更新了几张可爱的emoji，打算上传到个人主页的仓库里，所以在这里记录一下怎样将在其他文件夹内的文件上传到已有仓库中.</p>
<span id="more"></span>
<h2 id="1-初始化本地版本库"><a href="#1-初始化本地版本库" class="headerlink" title="1. 初始化本地版本库"></a>1. 初始化本地版本库</h2><p>在想上传的文件的所在文件夹初始化版本库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git init</span></span><br></pre></td></tr></table></figure>
<h2 id="2-拉取远程仓库并在本地合并"><a href="#2-拉取远程仓库并在本地合并" class="headerlink" title="2. 拉取远程仓库并在本地合并"></a>2. 拉取远程仓库并在本地合并</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git pull git@github.com:&lt;username&gt;/&lt;reponame&gt;.git</span></span><br></pre></td></tr></table></figure>
<h2 id="3-将要上传的文件提交到本地版本库"><a href="#3-将要上传的文件提交到本地版本库" class="headerlink" title="3. 将要上传的文件提交到本地版本库"></a>3. 将要上传的文件提交到本地版本库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git add &lt;filename&gt;</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> git commit -m <span class="string">&quot;Update files&quot;</span></span></span><br></pre></td></tr></table></figure>
<h2 id="4-创建一个与远程仓库分支同名的分支"><a href="#4-创建一个与远程仓库分支同名的分支" class="headerlink" title="4. 创建一个与远程仓库分支同名的分支"></a>4. 创建一个与远程仓库分支同名的分支</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git branch -M main</span></span><br></pre></td></tr></table></figure>
<h2 id="5-将本地库与远程库关联"><a href="#5-将本地库与远程库关联" class="headerlink" title="5. 将本地库与远程库关联"></a>5. 将本地库与远程库关联</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git remote add origin git@github.com:&lt;username&gt;/&lt;reponame&gt;.git</span></span><br></pre></td></tr></table></figure>
<h2 id="6-推送到远程仓库"><a href="#6-推送到远程仓库" class="headerlink" title="6. 推送到远程仓库"></a>6. 推送到远程仓库</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git push -u origin main</span></span><br></pre></td></tr></table></figure>
<h2 id="7-下次推送时"><a href="#7-下次推送时" class="headerlink" title="7. 下次推送时"></a>7. 下次推送时</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git push origin main</span></span><br></pre></td></tr></table></figure>
<h2 id="8-在远程仓库修改后再从本地推送"><a href="#8-在远程仓库修改后再从本地推送" class="headerlink" title="8. 在远程仓库修改后再从本地推送"></a>8. 在远程仓库修改后再从本地推送</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git pull --rebase origin main</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> git push origin main</span></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>技术</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git避免提交.DS_Store</title>
    <url>/2021/05/gitignore-dsstore/</url>
    <content><![CDATA[<p>今天发现在macOS上用Git提交时，会提示<code>.DS_Store</code>文件没有提交.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git status</span></span><br><span class="line">On branch master</span><br><span class="line">Untracked files:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)</span><br><span class="line">	.DS_Store</span><br><span class="line"></span><br><span class="line">nothing added to commit but untracked files present (use &quot;git add&quot; to track)</span><br></pre></td></tr></table></figure>
<p><code>.DS_Store</code>是macOS保存文件夹的自定义属性的隐藏文件，并没有什么用，但我也不太想禁止这个文件的生成. 所以可以用<code>.gitignore</code>文件配置需要忽略的文件.</p>
<span id="more"></span>
<h2 id="gitignore文件"><a href="#gitignore文件" class="headerlink" title=".gitignore文件"></a>.gitignore文件</h2><p>首先在当前目录下创建<code>.gitignore</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> touch .gitignore</span></span><br></pre></td></tr></table></figure>
<p>打开<code>.gitignore</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> open .gitignore</span></span><br></pre></td></tr></table></figure>
<p>在文件中添加以下内容并保存：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">*/.DS_Store</span><br></pre></td></tr></table></figure>
<p>完成以上步骤后，当前目录及其子目录的<code>.DS_Store</code>提交时就会被忽略了.</p>
<h2 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h2><p>为了该配置对所有仓库都生效，需要全局配置.</p>
<p>创建<code>~/.gitignore_global</code>文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> touch ~/.gitignore_global</span></span><br></pre></td></tr></table></figure>
<p>打开<code>~/.gitignore_global</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> open ~/.gitignore_global</span></span><br></pre></td></tr></table></figure>
<p>添加忽略配置，以下为常用配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.DS_Store</span><br><span class="line">.vscode</span><br></pre></td></tr></table></figure>
<p>把该文件设置为全局配置忽略文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git config --global core.excludesfile ~/.gitignore_global</span></span><br></pre></td></tr></table></figure>
<p>在根目录下的<code>.gitconfig</code>文件中添加以下内容同样可以达到上个步骤的目的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[core] </span><br><span class="line">excludesfile = /Users/&lt;username&gt;/.gitignore_global </span><br></pre></td></tr></table></figure>
<p>完成以上步骤后，配置成功.</p>
<h2 id="删除已提交的-DS-Store"><a href="#删除已提交的-DS-Store" class="headerlink" title="删除已提交的.DS_Store"></a>删除已提交的.DS_Store</h2><p>子目录中可能有已经提交的<code>.DS_Store</code>，所以删掉它们！</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatch</span></span><br><span class="line">rm &#x27;code/.DS_Store&#x27;</span><br></pre></td></tr></table></figure>
<p>最后提交一下<code>.gitignore</code>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">%</span><span class="bash"> git add .gitignore</span></span><br><span class="line"><span class="meta">%</span><span class="bash"> git commit -m <span class="string">&quot;deleted .DS_Store&quot;</span></span> </span><br><span class="line"><span class="meta">%</span><span class="bash"> git status</span></span><br><span class="line">On branch master</span><br><span class="line">nothing to commit, working tree clean</span><br></pre></td></tr></table></figure>
<p>大功告成，非常完美！</p>
]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机</title>
    <url>/2021/04/support-vector-machine/</url>
    <content><![CDATA[<p>本文将简述支持向量机(SVM)的原理与大致推导过程.</p>
<span id="more"></span>
<h2 id="1-支持向量与间隔"><a href="#1-支持向量与间隔" class="headerlink" title="1 支持向量与间隔"></a>1 支持向量与间隔</h2><p>给定训练样本$D=\{(\boldsymbol{x}_1,y_1),(\boldsymbol{x}_2,y_2),\dots,(\boldsymbol{x}_N,y_N)\},\boldsymbol{x}_i\in\mathbb{R}^L,y_i\in\{-1,+1\}$，其中输入数据的特征维度为$L$，类别标签为二分类. 直观上，我们希望在样本空间中用一个超平面将样本分为两类，该超平面可以表示为：</p>
<script type="math/tex; mode=display">
\boldsymbol{w}^T\boldsymbol{x}+b=0, \tag{1}</script><p>其中，$\boldsymbol{w}=[w_1;w_2;\dots,w_L]$为超平面的法向量.</p>
<p>为了能使超平面将样本很好地分类，我们希望最大化最小间隔，所以下面计算点到超平面的距离：</p>
<p>设$\boldsymbol{x}$投影到超平面上的点为$\boldsymbol{x}_0$，有$\boldsymbol{x}_{\perp}=\boldsymbol{x}-\boldsymbol{x}_0$与法向量$\boldsymbol{w}$平行. 则点$\boldsymbol{x}$到超平面的距离为$r=||\boldsymbol{x}_{\perp}||$.</p>
<script type="math/tex; mode=display">
\begin{align}
\boldsymbol{x}_{\perp}&=r\frac{\boldsymbol{w}}{||\boldsymbol{\boldsymbol{w}}||}, \newline
r&=\frac{\boldsymbol{w}^T\boldsymbol{x}_{\perp}}{||\boldsymbol{w}||} \newline
&=\frac{(\boldsymbol{w}^T\boldsymbol{x}+b)-(\boldsymbol{w}^T\boldsymbol{x}_0+b)}{||\boldsymbol{w}||} \newline
&=\frac{\boldsymbol{w}^T\boldsymbol{x}+b}{||\boldsymbol{w}||}. \tag{2}
\end{align}</script><p>若该超平面能将训练样本正确分类，则始终有：</p>
<script type="math/tex; mode=display">
y_i(\boldsymbol{w}^Tx_i+b)\geqslant1. \tag{3}</script><p>使等号成立的向量即”支持向量”(support vector).</p>
<p>由公式$(2)$，我们需要最大化两个类别的支持向量到超平面的距离之和$\frac{2}{||\boldsymbol{w}||}$，即”间隔”(margin). 最大化该距离等价于下面的优化问题，也即找到具有最大间隔的划分超平面：</p>
<script type="math/tex; mode=display">
\begin{align}
\min\limits_{\boldsymbol{w},b}\quad&{\frac{1}{2}||\boldsymbol{w}||^2} \newline
\text{s.t.}\quad&y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)\geqslant1,\quad i=1,2,\dots,m.
\end{align} \tag{4}</script><p>公式$(4)$即支持向量机的基本型.</p>
<h2 id="2-对偶问题"><a href="#2-对偶问题" class="headerlink" title="2 对偶问题"></a>2 对偶问题</h2><p>使用拉格朗日乘子法构造最优化问题$(4)$的”对偶问题”(dual problem)，来求解该最优化问题. 对式$(4)$对每个约束条件添加拉格朗日乘子$\alpha_i\geqslant0$，则该问题的拉格朗日函数为：</p>
<script type="math/tex; mode=display">
L(\boldsymbol{w},b,\boldsymbol{\alpha})=\frac{1}{2}||\boldsymbol{w}||^2+\sum_{i=1}^N\alpha_i(1-y_i(\boldsymbol{w}^T\boldsymbol{x}_i+b)), \tag{5}</script><p>其中，$\boldsymbol{\alpha}=(\alpha_1;\alpha_2;\dots;\alpha_N)$.</p>
<p>令$L(\boldsymbol{w},b,\boldsymbol{\alpha})$分别对$\boldsymbol{w}$和$b$的偏导为0，再代入式$(5)$中将$\boldsymbol{w}$与$b$消去，则得到了原优化问题的对偶问题：</p>
<script type="math/tex; mode=display">
\begin{align}
\max\limits_{\alpha}\quad&{\sum_{i=1}^N\alpha_i-\frac{1}{2}\sum_{i=1}^N\sum_{j=1}^N\alpha_i\alpha_jy_iy_j\boldsymbol{x}_i^T\boldsymbol{x}_j}. \newline
\text{s.t.}\quad&\sum_{i=1}^N\alpha_iy_i=0, \newline
&\alpha_i\geqslant0,\quad i=1,2,\dots,N.
\end{align} \tag{6}</script><p>此外，上式还需满足$K.K.T.$条件：</p>
<script type="math/tex; mode=display">
\begin{align}
&\alpha_i\geqslant0; \newline
&y_if(\boldsymbol{x}_i)-1\geqslant0; \newline
&\alpha_i(y_if(\boldsymbol{x}_i)-1)=0.
\end{align} \tag{7}</script><p>解出$\boldsymbol{\alpha}$后得到模型：</p>
<script type="math/tex; mode=display">
f(\boldsymbol{x})=\sum_{i=1}^N\alpha_iy_i\boldsymbol{x}_i^T\boldsymbol{x}+b. \tag{8}</script><h2 id="3-核函数"><a href="#3-核函数" class="headerlink" title="3 核函数"></a>3 核函数</h2><p>注意到若样本$\boldsymbol{x}$在原始空间中线性不可分，那么我们希望将样本从原始空间映射到一个可以被线性可分的更高维的空间，因此通过映射后的模型可以表示为：</p>
<script type="math/tex; mode=display">
f(\boldsymbol{x})=\boldsymbol{w}^T\phi(\boldsymbol{x})+b. \tag{9}</script><p>但求解式$(9)$的对偶问题需要计算$\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j)$，起计算代价通常很大. 所以我们设想一个函数：</p>
<script type="math/tex; mode=display">
\kappa(\boldsymbol{x}_i,\boldsymbol{x}_j)=\langle\phi(\boldsymbol{x}_i)^T\phi(\boldsymbol{x}_j)\rangle. \tag{10}</script><p>将式$(10)$代入式$(6)$，重写以后求解可得到模型在使用核函数时的表示：</p>
<script type="math/tex; mode=display">
f(\boldsymbol{x})=\sum_{i=1}^N\alpha_yy_i\kappa(\boldsymbol{x},\boldsymbol{x}_i)+b. \tag{11}</script><p>公式$(10)$被称为”核函数”(kernel function).</p>
<h2 id="4-折页损失"><a href="#4-折页损失" class="headerlink" title="4 折页损失"></a>4 折页损失</h2><p>通常，由于很难恰巧找到一个可以将所有样本分类的超平面，我们引入了软间隔的概念来放松约束条件. 在这种情况下，一种常用的损失函数是折页损失 (Hinge Loss)：</p>
<script type="math/tex; mode=display">
l_{hinge}(z)=\max(0,1-z). \tag{12}</script>]]></content>
      <categories>
        <category>2021</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas小技巧</title>
    <url>/2000/11/pandas-tricks/</url>
    <content><![CDATA[<p>本文记录数据处理过程中用到的各种Pandas小技巧. ( ´▽` )ﾉ</p>
<p>长期更新！</p>
<span id="more"></span>
<h2 id="统计某列元素类别"><a href="#统计某列元素类别" class="headerlink" title="统计某列元素类别"></a>统计某列元素类别</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = <span class="built_in">list</span>(<span class="built_in">set</span>(df[<span class="string">&#x27;feature&#x27;</span>]))</span><br></pre></td></tr></table></figure>
<h2 id="统计某列各类元素数量"><a href="#统计某列各类元素数量" class="headerlink" title="统计某列各类元素数量"></a>统计某列各类元素数量</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = df[<span class="string">&#x27;feature&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>
<p>更进一步，如果我们想查看该列元素的分布，首先根据该列的索引排序</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = df[<span class="string">&#x27;feature&#x27;</span>].value_counts().sort_index()</span><br></pre></td></tr></table></figure>
<p>若要获取index列表：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a.index</span><br></pre></td></tr></table></figure>
<p>最终可以画出柱状图统计</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">plt.bar(a.index, a)</span><br></pre></td></tr></table></figure>
<h2 id="删除指定行"><a href="#删除指定行" class="headerlink" title="删除指定行"></a>删除指定行</h2><p>实际上是通过获取满足条件的索引列表，然后按索引删除.</p>
<p>假设要删除<code>length</code>一列小于0的项.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = df.drop(df[df[<span class="string">&#x27;length&#x27;</span>] &lt; <span class="number">0</span>].index)</span><br></pre></td></tr></table></figure>
<h2 id="替换特定值"><a href="#替换特定值" class="headerlink" title="替换特定值"></a>替换特定值</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;feature&#x27;</span>].replace(&lt;original&gt;, &lt;replaced&gt;, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="按索引删除某一列"><a href="#按索引删除某一列" class="headerlink" title="按索引删除某一列"></a>按索引删除某一列</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">&#x27;feature&#x27;</span> <span class="keyword">in</span> df.columns.values:</span><br><span class="line">  	train.drop(<span class="string">&#x27;feature&#x27;</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>2000</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>NumPy小技巧</title>
    <url>/2000/11/numpy-tricks/</url>
    <content><![CDATA[<p>本文记录写Python过程中用到的各种NumPy小技巧. (´･ω･`)</p>
<p>长期更新！</p>
<span id="more"></span>
<h2 id="对某一维应用相同的函数"><a href="#对某一维应用相同的函数" class="headerlink" title="对某一维应用相同的函数"></a>对某一维应用相同的函数</h2><p>事实上，map也可以做到，但是我在class里用map的时候遇到了一点小问题，遂用NumPy.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.apply_along_axis(function, axis, arr)</span><br></pre></td></tr></table></figure>
<h2 id="满足条件元素的下标"><a href="#满足条件元素的下标" class="headerlink" title="满足条件元素的下标"></a>满足条件元素的下标</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.argwhere(conditions)</span><br></pre></td></tr></table></figure>
<h2 id="各种随机数的生成"><a href="#各种随机数的生成" class="headerlink" title="各种随机数的生成"></a>各种随机数的生成</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># axb的数组，元素为[0, 1]之间均匀分布的随机样本</span></span><br><span class="line"><span class="comment"># 如果不指明数组大小，则返回一个随机数</span></span><br><span class="line">np.random.rand(a, b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组元素符合标准正态分布N(0, 1)</span></span><br><span class="line">np.random.randn(a, b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数组元素为[low, high)之间离散均匀分布的整数</span></span><br><span class="line">np.random.randint(low, high, size)</span><br></pre></td></tr></table></figure>
<h2 id="开一个与原矩阵形状相同的新矩阵"><a href="#开一个与原矩阵形状相同的新矩阵" class="headerlink" title="开一个与原矩阵形状相同的新矩阵"></a>开一个与原矩阵形状相同的新矩阵</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">new = np.empty_like(original)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>2000</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>愿原力与你同在！</title>
    <url>/2000/05/may-the-force-be-with-you/</url>
    <content><![CDATA[<p>这只是一篇无聊的测试 &gt;_&lt;</p>
<p>May the Force be with you!</p>
<span id="more"></span>
<h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><div class="table-container">
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>C</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>y</td>
<td>z</td>
</tr>
<tr>
<td>a</td>
<td>s</td>
<td>d</td>
</tr>
<tr>
<td>q</td>
<td>w</td>
<td>e</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>2000</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
